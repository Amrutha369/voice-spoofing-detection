{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPBG+xtgFl8rrnkaIXMzgoK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amrutha369/voice-spoofing-detection/blob/main/voice_spoofing_detection_using_cnn_Multiclass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5cdvShFrPHW",
        "outputId": "f837d1dc-bfba-46f6-9831-1c8c4db2d549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.3.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install tensorflow-io\n",
        "import os\n",
        "import pandas as pd # data manipulation and analysis\n",
        "import matplotlib.pyplot as plt #plotting library\n",
        "%matplotlib inline\n",
        "import numpy as np #numerical computing\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "import seaborn as sns # statistical data visualization\n",
        "from IPython.display import Audio\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV9lHZv1rZIt",
        "outputId": "39de6da4-e137-48fa-e424-3209fb577206"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.36.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-io) (0.36.0)\n",
            "Installing collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.36.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Audio params\n",
        "SAMPLE_RATE = 16000\n",
        "DURATION = 20.0 # duration in second\n",
        "AUDIO_LEN = int(SAMPLE_RATE * DURATION)\n",
        "\n",
        "# Spectrogram params\n",
        "N_MELS = 128 # freq axis\n",
        "N_FFT = 2048\n",
        "SPEC_WIDTH = 256 #\n",
        "HOP_LEN = 512 # non-overlap region\n",
        "FMAX = SAMPLE_RATE//2 # max frequency\n",
        "\n",
        "# CNN params\n",
        "NUM_CLASSES = 3 # bonafide or spoof\n",
        "BATCH_SIZE = 16 # The number of samples processed in each training batch\n",
        "EPOCHS = 100 # the number of times the entire dataset is passed forward and backward through the neural network during training.\n",
        "LEARNING_RATE = 0.0001 # adjust based on your model performance\n"
      ],
      "metadata": {
        "id": "jRDGm7HMrZWu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HfkewpCsnaj",
        "outputId": "4d3638b1-a44b-47c4-8ee2-f636b821acc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory and protocol definitions\n",
        "base_path = '/content/drive/MyDrive/dataset/LA'\n",
        "protocol_dir = os.path.join(base_path, 'ASVspoof2019_LA_cm_protocols')\n",
        "train_dir = os.path.join(base_path, 'ASVspoof2019_LA_train', 'flac')\n",
        "dev_dir = os.path.join(base_path, 'ASVspoof2019_LA_dev', 'flac')\n",
        "eval_dir = os.path.join(base_path, 'ASVspoof2019_LA_eval', 'flac')"
      ],
      "metadata": {
        "id": "aMyzkGSNsndF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to form the full path of a file\n",
        "def get_file_path(directory, filename):\n",
        "    return os.path.join(directory, f'{filename}.flac')"
      ],
      "metadata": {
        "id": "ncAOykjrsngb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read the dataset\n",
        "def read_dataset(protocol_path, directory):\n",
        "    \"\"\"Reads the dataset from a protocol file and returns a DataFrame.\"\"\"\n",
        "    df = pd.read_csv(protocol_path, sep=' ', header=None, names=['speaker_id', 'filename', 'system_id', 'null', 'class_name'])\n",
        "    df['filepath'] = df['filename'].apply(lambda x: get_file_path(directory, x))\n",
        "    df.drop('null', axis=1, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "# Function to convert class_name to integer\n",
        "def label_to_int(class_name):\n",
        "    if class_name == 'real':\n",
        "        return 0\n",
        "    elif class_name == 'synthesised':\n",
        "        return 1\n",
        "    elif class_name == 'converted':\n",
        "        return 2\n",
        "    else:\n",
        "        return -1  # Handle unknown classes\n",
        "\n",
        "# Add target column and subset to DataFrame\n",
        "def add_columns(df, subset):\n",
        "    df['target'] = df['class_name'].apply(label_to_int)\n",
        "    df['subset'] = subset\n",
        "    return df\n",
        "\n",
        "# Take samples from each DataFrame\n",
        "def sample_data_multiclass(df, n_synthesised, n_bonafide, n_converted):\n",
        "    synthesised = df[df['class_name'] == 'synthesised'].head(n_synthesised)\n",
        "    bonafide = df[df['class_name'] == 'real'].head(n_bonafide)\n",
        "    converted = df[df['class_name'] == 'converted'].head(n_converted)\n",
        "    return pd.concat([synthesised, bonafide, converted])\n",
        "\n",
        "# Directory and protocol definitions\n",
        "base_path = '/content/drive/MyDrive/dataset/LA'\n",
        "protocol_dir = os.path.join(base_path, 'ASVspoof2019_LA_cm_protocols')\n",
        "train_dir = os.path.join(base_path, 'ASVspoof2019_LA_train', 'flac')\n",
        "dev_dir = os.path.join(base_path, 'ASVspoof2019_LA_dev', 'flac')\n",
        "eval_dir = os.path.join(base_path, 'ASVspoof2019_LA_eval', 'flac')\n",
        "\n",
        "# Create DataFrames for each dataset\n",
        "train_df = read_dataset(os.path.join(protocol_dir, 'ASVspoof2019.LA.cm.train.trn.txt'), train_dir)\n",
        "dev_df = read_dataset(os.path.join(protocol_dir, 'ASVspoof2019.LA.cm.dev.trl.txt'), dev_dir)\n",
        "eval_df = read_dataset(os.path.join(protocol_dir, 'ASVspoof2019.LA.cm.eval.trl.txt'), eval_dir)\n",
        "\n",
        "# Add columns to each DataFrame\n",
        "train_df = add_columns(train_df, 'train')\n",
        "dev_df = add_columns(dev_df, 'dev')\n",
        "eval_df = add_columns(eval_df, 'eval')\n",
        "\n",
        "# Take samples from each DataFrame by a different number\n",
        "train_df = sample_data_multiclass(train_df, 525, 70, 70)\n",
        "dev_df = sample_data_multiclass(dev_df, 150, 15, 15)\n",
        "eval_df = sample_data_multiclass(eval_df, 150, 15, 15)"
      ],
      "metadata": {
        "id": "BqBk4VejxZRn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine three dataframes into one dataframe\n",
        "data_df = pd.concat([train_df, dev_df, eval_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "P-B03xmtyEQP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.head(len(data_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "t_zIIPIQxZUg",
        "outputId": "bcd859f6-a605-4262-ed8e-558b53766ee9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    speaker_id      filename system_id   class_name  \\\n",
              "0      LA_0098  LA_T_1000648         -  synthesised   \n",
              "1      LA_0090  LA_T_1001169         -  synthesised   \n",
              "2      LA_0098  LA_T_1001718         -  synthesised   \n",
              "3      LA_0085  LA_T_1002656         -  synthesised   \n",
              "4      LA_0085  LA_T_1004407         -  synthesised   \n",
              "..         ...           ...       ...          ...   \n",
              "444    LA_0098  LA_T_8794062         -    converted   \n",
              "445    LA_0098  LA_T_8806933         -    converted   \n",
              "446    LA_0098  LA_T_8827497         -    converted   \n",
              "447    LA_0098  LA_T_8858210         -    converted   \n",
              "448    LA_0098  LA_T_8881061         -    converted   \n",
              "\n",
              "                                              filepath  target subset  \n",
              "0    /content/drive/MyDrive/dataset/LA/ASVspoof2019...       1  train  \n",
              "1    /content/drive/MyDrive/dataset/LA/ASVspoof2019...       1  train  \n",
              "2    /content/drive/MyDrive/dataset/LA/ASVspoof2019...       1  train  \n",
              "3    /content/drive/MyDrive/dataset/LA/ASVspoof2019...       1  train  \n",
              "4    /content/drive/MyDrive/dataset/LA/ASVspoof2019...       1  train  \n",
              "..                                                 ...     ...    ...  \n",
              "444  /content/drive/MyDrive/dataset/LA/ASVspoof2019...       2   eval  \n",
              "445  /content/drive/MyDrive/dataset/LA/ASVspoof2019...       2   eval  \n",
              "446  /content/drive/MyDrive/dataset/LA/ASVspoof2019...       2   eval  \n",
              "447  /content/drive/MyDrive/dataset/LA/ASVspoof2019...       2   eval  \n",
              "448  /content/drive/MyDrive/dataset/LA/ASVspoof2019...       2   eval  \n",
              "\n",
              "[449 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2b04244-db70-4c1d-9ab4-c7b09daddb4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker_id</th>\n",
              "      <th>filename</th>\n",
              "      <th>system_id</th>\n",
              "      <th>class_name</th>\n",
              "      <th>filepath</th>\n",
              "      <th>target</th>\n",
              "      <th>subset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LA_0098</td>\n",
              "      <td>LA_T_1000648</td>\n",
              "      <td>-</td>\n",
              "      <td>synthesised</td>\n",
              "      <td>/content/drive/MyDrive/dataset/LA/ASVspoof2019...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LA_0090</td>\n",
              "      <td>LA_T_1001169</td>\n",
              "      <td>-</td>\n",
              "      <td>synthesised</td>\n",
              "      <td>/content/drive/MyDrive/dataset/LA/ASVspoof2019...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LA_0098</td>\n",
              "      <td>LA_T_1001718</td>\n",
              "      <td>-</td>\n",
              "      <td>synthesised</td>\n",
              "      <td>/content/drive/MyDrive/dataset/LA/ASVspoof2019...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LA_0085</td>\n",
              "      <td>LA_T_1002656</td>\n",
              "      <td>-</td>\n",
              "      <td>synthesised</td>\n",
              "      <td>/content/drive/MyDrive/dataset/LA/ASVspoof2019...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LA_0085</td>\n",
              "      <td>LA_T_1004407</td>\n",
              "      <td>-</td>\n",
              "      <td>synthesised</td>\n",
              "      <td>/content/drive/MyDrive/dataset/LA/ASVspoof2019...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>444</th>\n",
              "      <td>LA_0098</td>\n",
              "      <td>LA_T_8794062</td>\n",
              "      <td>-</td>\n",
              "      <td>converted</td>\n",
              "      <td>/content/drive/MyDrive/dataset/LA/ASVspoof2019...</td>\n",
              "      <td>2</td>\n",
              "      <td>eval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>LA_0098</td>\n",
              "      <td>LA_T_8806933</td>\n",
              "      <td>-</td>\n",
              "      <td>converted</td>\n",
              "      <td>/content/drive/MyDrive/dataset/LA/ASVspoof2019...</td>\n",
              "      <td>2</td>\n",
              "      <td>eval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>LA_0098</td>\n",
              "      <td>LA_T_8827497</td>\n",
              "      <td>-</td>\n",
              "      <td>converted</td>\n",
              "      <td>/content/drive/MyDrive/dataset/LA/ASVspoof2019...</td>\n",
              "      <td>2</td>\n",
              "      <td>eval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>LA_0098</td>\n",
              "      <td>LA_T_8858210</td>\n",
              "      <td>-</td>\n",
              "      <td>converted</td>\n",
              "      <td>/content/drive/MyDrive/dataset/LA/ASVspoof2019...</td>\n",
              "      <td>2</td>\n",
              "      <td>eval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>LA_0098</td>\n",
              "      <td>LA_T_8881061</td>\n",
              "      <td>-</td>\n",
              "      <td>converted</td>\n",
              "      <td>/content/drive/MyDrive/dataset/LA/ASVspoof2019...</td>\n",
              "      <td>2</td>\n",
              "      <td>eval</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>449 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2b04244-db70-4c1d-9ab4-c7b09daddb4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2b04244-db70-4c1d-9ab4-c7b09daddb4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2b04244-db70-4c1d-9ab4-c7b09daddb4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3e7b7a97-2614-4fa6-8594-a4d0b32837c6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3e7b7a97-2614-4fa6-8594-a4d0b32837c6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3e7b7a97-2614-4fa6-8594-a4d0b32837c6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_df",
              "summary": "{\n  \"name\": \"data_df\",\n  \"rows\": 449,\n  \"fields\": [\n    {\n      \"column\": \"speaker_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 81,\n        \"samples\": [\n          \"LA_0109\",\n          \"LA_0098\",\n          \"LA_0101\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 449,\n        \"samples\": [\n          \"LA_T_1121974\",\n          \"LA_T_1142053\",\n          \"LA_T_1287623\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"system_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"synthesised\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filepath\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 449,\n        \"samples\": [\n          \"/content/drive/MyDrive/dataset/LA/ASVspoof2019_LA_train/flac/LA_T_1121974.flac\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "def audio_to_spectrogram(filepath):\n",
        "    # Load audio file using librosa\n",
        "    audio, sample_rate = librosa.load(filepath)\n",
        "\n",
        "    # Normalize the audio\n",
        "    audio_norm = (audio - np.min(audio)) / (np.max(audio) - np.min(audio))\n",
        "    # A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time.\n",
        "    # Compute the spectrogram using librosa\n",
        "    spectrogram = librosa.feature.melspectrogram(y=audio_norm, sr=sample_rate)\n",
        "\n",
        "    # Convert the spectrogram to decibels\n",
        "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "\n",
        "    # Add channel dimension\n",
        "    spectrogram_db = np.expand_dims(spectrogram_db, axis=-1)\n",
        "\n",
        "    # Resize spectrogram to the specified size\n",
        "    image = tf.image.resize(spectrogram_db, [SPEC_WIDTH, N_MELS])\n",
        "\n",
        "    return image\n",
        "\n",
        "# Adding the spectrogram column to the DataFrame\n",
        "data_df['spectrogram'] = data_df['filepath'].apply(audio_to_spectrogram)\n"
      ],
      "metadata": {
        "id": "aoOEEboxxZXB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data based on the 'subset' column\n",
        "train_data = data_df[data_df['subset'] == 'train']\n",
        "dev_data = data_df[data_df['subset'] == 'dev']\n",
        "eval_data = data_df[data_df['subset'] == 'eval']\n",
        "\n",
        "# Converting the list of spectrograms into NumPy arrays\n",
        "X_train = np.stack(train_data['spectrogram'].to_list())\n",
        "X_dev = np.stack(dev_data['spectrogram'].to_list())\n",
        "X_eval = np.stack(eval_data['spectrogram'].to_list())\n",
        "\n",
        "# Converting target into NumPy arrays\n",
        "y_train = train_data['target'].to_numpy()\n",
        "y_dev = dev_data['target'].to_numpy()\n",
        "y_eval = eval_data['target'].to_numpy()"
      ],
      "metadata": {
        "id": "gGCAy3O-xZZc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")#Contains target labels\n",
        "print(f\"X_dev shape: {X_dev.shape}\")\n",
        "print(f\"y_dev shape: {y_dev.shape}\")\n",
        "print(f\"X_eval shape: {X_eval.shape}\")\n",
        "print(f\"y_eval shape: {y_eval.shape}\")"
      ],
      "metadata": {
        "id": "LWRLTHXMxZb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6086d075-be49-40bc-d8a5-bb10cf0a5d24"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (315, 256, 128, 1)\n",
            "y_train shape: (315,)\n",
            "X_dev shape: (67, 256, 128, 1)\n",
            "y_dev shape: (67,)\n",
            "X_eval shape: (67, 256, 128, 1)\n",
            "y_eval shape: (67,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def cnn_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    # 1st conv layer\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    # 2nd conv layer\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    # 3rd conv layer\n",
        "    model.add(Conv2D(32, (2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    # 4th conv layer\n",
        "    model.add(Conv2D(64, (2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    # Additional dense layer\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    # Output layer for multiclass classification\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    # Compile the model with Adam optimizer\n",
        "    optimizer = Adam(learning_rate=LEARNING_RATE)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Convert target labels to one-hot encoding for multiclass classification\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert target labels to one-hot encoding\n",
        "y_train_categorical = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
        "y_dev_categorical = to_categorical(y_dev, num_classes=NUM_CLASSES)\n",
        "y_eval_categorical = to_categorical(y_eval, num_classes=NUM_CLASSES)\n",
        "\n",
        "# Create the multiclass CNN model with Adam optimizer\n",
        "multiclass_cnn_model = create_multiclass_cnn_model((X_train.shape[1], X_train.shape[2], 1), NUM_CLASSES)\n",
        "\n",
        "# Train the multiclass CNN model\n",
        "multiclass_cnn_model.fit(X_train, y_train_categorical, epochs=50, batch_size=16)\n",
        "\n",
        "# Compute accuracy on training data\n",
        "train_accuracy = multiclass_cnn_model.evaluate(X_train, y_train_categorical)[1]\n",
        "print(f\"Accuracy on training data: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Compute accuracy on validation data\n",
        "val_accuracy = multiclass_cnn_model.evaluate(X_dev, y_dev_categorical)[1]\n",
        "print(f'Accuracy on validation data: {val_accuracy * 100:.2f}%')\n",
        "\n",
        "# Compute accuracy on test data\n",
        "test_accuracy = multiclass_cnn_model.evaluate(X_eval, y_eval_categorical)[1]\n",
        "print(f'Accuracy on test data: {test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "di09nrZQxZez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa6fb76-ad28-491c-fcb8-89bbceb9122c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 3s 16ms/step - loss: 1.0070 - accuracy: 0.5429\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.6383 - accuracy: 0.7111\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.4704 - accuracy: 0.8286\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.3714 - accuracy: 0.8381\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2879 - accuracy: 0.8857\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2333 - accuracy: 0.9079\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2209 - accuracy: 0.9270\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1668 - accuracy: 0.9524\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1659 - accuracy: 0.9429\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1232 - accuracy: 0.9714\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0917 - accuracy: 0.9683\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1067 - accuracy: 0.9651\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0896 - accuracy: 0.9714\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0773 - accuracy: 0.9778\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0915 - accuracy: 0.9587\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0606 - accuracy: 0.9841\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0597 - accuracy: 0.9778\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0689 - accuracy: 0.9746\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0721 - accuracy: 0.9841\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0738 - accuracy: 0.9714\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0465 - accuracy: 0.9873\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0575 - accuracy: 0.9873\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0515 - accuracy: 0.9810\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0359 - accuracy: 0.9873\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0327 - accuracy: 0.9937\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0325 - accuracy: 0.9873\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0331 - accuracy: 0.9873\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9937\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0341 - accuracy: 0.9873\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0337 - accuracy: 0.9905\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0261 - accuracy: 0.9905\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 0.9968\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0247 - accuracy: 0.9905\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0249 - accuracy: 0.9905\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0250 - accuracy: 0.9937\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0213 - accuracy: 0.9937\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0352 - accuracy: 0.9937\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0175 - accuracy: 0.9968\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0188 - accuracy: 0.9937\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0395 - accuracy: 0.9873\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9937\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0219 - accuracy: 0.9968\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 0.9937\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0162 - accuracy: 0.9937\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0240 - accuracy: 0.9937\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9968\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.9968\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 0.9968\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.3441e-04 - accuracy: 1.0000\n",
            "Accuracy on training data: 100.00%\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1088 - accuracy: 0.9701\n",
            "Accuracy on validation data: 97.01%\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2057 - accuracy: 0.9701\n",
            "Accuracy on test data: 97.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "multiclass_cnn_model.save('/content/drive/MyDrive/save/voice-spoofing-detection-using-cnn-Multiclass.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NElZsXY5kekj",
        "outputId": "e777f6cb-9760-42b5-b015-aaa07554bbaf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "sample_audio_file_path = \"/content/drive/MyDrive/dataset/LA/ASVspoof2019_LA_eval/flac/LA_T_6904517.flac\"\n",
        "\n",
        "print(\"Sample audio file:\", sample_audio_file_path)\n",
        "model_path = \"/content/drive/MyDrive/save/voice-spoofing-detection-using-cnn-Multiclass.h5\"  # Replace with actual path\n",
        "multiclass_cnn_model = load_model(model_path)\n",
        "# Creating spectrogram for the sample audio file\n",
        "sample_audio_spectrogram = audio_to_spectrogram(sample_audio_file_path)\n",
        "X_new = np.expand_dims(sample_audio_spectrogram, axis=0)\n",
        "\n",
        "# Performing prediction\n",
        "y_pred = multiclass_cnn_model.predict(X_new)\n",
        "\n",
        "# Convert probabilities to classes by selecting the class with the highest probability\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Map predicted classes to labels\n",
        "class_labels = ['real', 'synthesised', 'converted']  # Update with your actual class labels\n",
        "y_pred_labels = [class_labels[pred] for pred in y_pred_classes]\n",
        "print(\"Predicted class:\", y_pred_labels[0])"
      ],
      "metadata": {
        "id": "EnhgVQbMxZhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a72876d2-2861-4a44-89f7-4c45a36bbc28"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample audio file: /content/drive/MyDrive/dataset/LA/ASVspoof2019_LA_eval/flac/LA_T_6904517.flac\n",
            "1/1 [==============================] - 0s 313ms/step\n",
            "Predicted class: real\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xqBnjIYRxZlF"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}